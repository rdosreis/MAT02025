---
title: "MAT02025 - Amostragem 1"
subtitle: "O erro quadrático médio"
fontsize: 10pt
author: |
  | Rodrigo Citton P. dos Reis
  | `citton.padilha@ufrgs.br`
institute: |
  | \textsc{Universidade Federal do Rio Grande do Sul}
  | \textsc{Instituto de Matemática e Estatística}
  | \textsc{Departamento de Estatística}
date: |
  | Porto Alegre, 2021
header-includes:
  - \titlegraphic{\hfill\includegraphics[height=1.5cm]{logos/Logo-40-anos-estatistica.png}}
---

# O erro quadrático médio

## O erro quadrático médio {.allowframebreaks}

- Para comparar um estimador enviesado com um estimador imparcial, ou dois estimadores com diferentes valores de enviesamento, um critério útil é o \structure{erro quadrático médio} __(EQM)__ da estimativa, medido a partir do valor da população que está sendo estimado.
- Formalmente

\begin{eqnarray*}
\textcolor{blue}{EQM(\hat{\theta})} &=& \textcolor{blue}{\E(\hat{\theta} - \theta)^2} \\
&=& \E\{[\hat{\theta} - \textcolor{red}{\E(\hat{\theta})}] + [\textcolor{red}{\E(\hat{\theta})} - \theta]\}^2 \\
&=& \E\{[\hat{\theta} - \E(\hat{\theta})]^2 + 2[\hat{\theta} - \E(\hat{\theta})][\E(\hat{\theta}) - \theta] + [\E(\hat{\theta}) - \theta]^2\} \\
&=& \E\{[\hat{\theta} - \E(\hat{\theta})]^2\} + 2[\E(\hat{\theta}) - \theta]\E[\hat{\theta} - \E(\hat{\theta})] + \E[\E(\hat{\theta}) - \theta]^2 \\
&=& \Var(\hat{\theta}) + 2[\E(\hat{\theta}) - \theta]\textcolor{red}{[\E(\hat{\theta}) - \E(\hat{\theta})]} + [B(\hat{\theta})]^2 \\
&=& \textcolor{blue}{\Var(\hat{\theta}) + [B(\hat{\theta})]^2}.
\end{eqnarray*}

\framebreak

- Note que se um estimador $\hat{\theta}$ é não enviesado para $\theta$, então

$$
EQM(\hat{\theta}) = \Var(\hat{\theta}) + [\textcolor{red}{0}]^2 = \Var(\hat{\theta}) = \sigma^2_{\hat{\theta}}.
$$

- No exemplo da aula passada, considerando o parâmetro populacional de interesse como a média, $\mu$, temos $EQM(\hat{\mu}) = \sigma^2_{\hat{\mu}} + B^2$, em que $B = m - \mu$.

\framebreak

- O uso do EQM como critério de precisão de um estimador equivale a considerar equivalentes duas estimativas que têm o mesmo erro quadrático médio.
- Isso não é inteiramente verdadeiro, porque a distribuição de frequência de erros $(\hat{\mu} - \mu)$ não será a mesma para dois estimadores, caso eles apresentem viéses de valores diferentes.
- Entretanto, \structure{Hansen, Hurwitz e Madow (1953)}\footnote{Hansen, M. H., Hurwitz, W. N. e Madow, W. G. (1953) {\bf Sample Survey methods and theory}, John Wiley \& Sons, Nova York, Vol. I, pg. 58.} que se $B/\sigma$ for menor que cerca que $0,5$, as duas distribuições de frequência são quase idênticas em relação aos erros __absolutos__ $|\hat{\mu} - \mu|$ de tamanhos diferentes.

## O erro quadrático médio {.allowframebreaks}

- Mais uma vez suponha que $\hat{\mu}$ tem uma distribuição aproximadamente normal com média $m = \E(\hat{\mu})$ e desvio padrão $\sigma = \sigma_{\hat{\mu}}$. Ainda, denote $EQM = EQM(\hat{\mu}) = \sigma^2 + B^2$
- Então

$$
\Pr\left(|\hat{\mu} - \mu| \geq  k\sqrt{EQM}\right) = \frac{1}{\sigma\sqrt{2\pi}}\int_{\mu + k\sqrt{EQM}}^{\infty}{e^{-(\hat{\mu} - m)^2/2\sigma^2}d\hat{\mu}}.
$$

\framebreak

```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}

f <- function(t){ 1 / sqrt(2*pi) * exp( - t^ 2/ 2) }

low <- function(b){integrate(f, lower = -Inf, upper = -sqrt(1 + b^2) - b)$value}
upp <- function(b){integrate(f, lower = sqrt(1 + b^2) - b, upper = Inf)$value}
low.1 <- Vectorize(low)
upp.1 <- Vectorize(upp)

low <- function(b){integrate(f, lower = -Inf, upper = -1.96*sqrt(1 + b^2) - b)$value}
upp <- function(b){integrate(f, lower = 1.96*sqrt(1 + b^2) - b, upper = Inf)$value}
low.2 <- Vectorize(low)
upp.2 <- Vectorize(upp)

low <- function(b){integrate(f, lower = -Inf, upper = -2.576*sqrt(1 + b^2) - b)$value}
upp <- function(b){integrate(f, lower = 2.576*sqrt(1 + b^2) - b, upper = Inf)$value}
low.3 <- Vectorize(low)
upp.3 <- Vectorize(upp)


B.sigma <- c(seq(0, 0.6, by = 0.1), seq(1, 3, by = 0.5))

pt.1 <- low.1(B.sigma) + upp.1(B.sigma)
pt.2 <- low.2(B.sigma) + upp.2(B.sigma)
pt.3 <- low.3(B.sigma) + upp.3(B.sigma)

df <- data.frame(B.sigma, pt.1, pt.2, pt.3)
df[11:12,4] <- NA

options(knitr.kable.NA = '-')

knitr::kable(x = df,
             format = "markdown",
             digits = c(2, 2, 3, 4),
             align = "cccc",
             col.names = c("$B/\\sigma$",
                           "$\\geq \\sqrt{EQM}$",
                           "$\\geq 1,96\\sqrt{EQM}$",
                           "$\\geq 2,576\\sqrt{EQM}$"),
             caption = "Proporção de casos em que o valor verdadeiro, $\\mu$, não está incluído no intervalo $\\hat{\\mu} \\pm k\\sqrt{EQM}$, para diferentes níveis de viés em $\\hat{\\mu}$")

```

\framebreak

```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

B.sigma <- c(seq(0, 0.6, by = 0.1), seq(1, 3, by = 0.5))

pt.1 <- low.1(B.sigma) + upp.1(B.sigma)
pt.2 <- low.2(B.sigma) + upp.2(B.sigma)
pt.3 <- low.3(B.sigma) + upp.3(B.sigma)

df <- data.frame(B.sigma, pt.1, pt.2, pt.3)

plot(x = df$B.sigma,
     y = df$pt.1,
     type = "b",
     lwd = 2,
     col = "red",
     ylim = c(0, 0.6),
     xlab = expression(B/sigma),
     ylab = expression(paste("Probabilidade de erro ", (hat(mu) - mu) )),
     main = expression(paste("Efeito do viés sobre a probabilidade de um erro maior que ",  k*sqrt(EQM) )) )
lines(x = df$B.sigma,
      y = df$pt.2,
      type = "b",
      lwd = 2,
      col = "darkorange")
lines(x = df$B.sigma,
      y = df$pt.3,
      type = "b",
      lwd = 2,
      col = "pink2")
abline(v = 0.5, lty = 2, lwd = 2, col = "darkgrey")
legend("topright",
       legend = c(expression("">= sqrt("EQM")), expression("">= 1.96*sqrt("EQM")), expression("">= 2.576*sqrt("EQM"))),
       lwd = 2, col = c("red", "darkorange", "pink2"), bty = "n")

```

## Comentários {.allowframebreaks}

- Esses resultados, para muitos propósitos práticos, concordam com as interpretações baseadas nos múltiplos correspondentes do desvio padrão quando uma estimativa não enviesada é usada.
    + Ou seja, quando $\sqrt{EQM} = \sqrt{\sigma^2 + B^2} = \sqrt{\sigma^2 + 0} = \sigma$.
- Da aula passada, temos

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='60%', paged.print=FALSE}

knitr::include_graphics(here::here('images', 'slide-aula-04.png'))

```

\framebreak

\footnotesize

- Devido à dificuldade de garantir que nenhum viés insuspeitado entre nas estimativas, geralmente falaremos da \structure{precisão} de uma estimativa em vez de sua \structure{acurácia} (exatidão).
- A acurácia se refere ao tamanho dos desvios da verdadeira média $\mu$, enquanto a precisão se refere ao tamanho dos desvios da média $m$ obtida pela aplicação repetida do procedimento de amostragem.

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='60%', paged.print=FALSE}

knitr::include_graphics(here::here('images', 'acuracia_precisao.png'))

```

\framebreak

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='100%', paged.print=FALSE}

knitr::include_graphics(here::here('images', 'acuracia_precisao-2.png'))

```

- \structure{Pergunta:} o que podemos concluir sobre $\hat{\theta}_1$, $\hat{\theta}_2$ e $\hat{\theta}_3$?

# Exercícios

## Para casa

- __Atividade de avaliação I__.

## Próxima aula

- Amostragem aleatória simples;
- Definições e notação.

## Por hoje é só!

\begin{center}
{\bf Bons estudos!}
\end{center}

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='50%', out.height='50%', paged.print=FALSE}

knitr::include_graphics(here::here('images', 'Statistically-Insignificant-errorbar.jpg'))

```


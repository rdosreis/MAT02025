---
title: "MAT02025 - Amostragem 1"
subtitle: "AAS: distribuição das estimativas de $P$"
fontsize: 10pt
author: |
  | Rodrigo Citton P. dos Reis
  | `citton.padilha@ufrgs.br`
institute: |
  | \textsc{Universidade Federal do Rio Grande do Sul}
  | \textsc{Instituto de Matemática e Estatística}
  | \textsc{Departamento de Estatística}
date: |
  | Porto Alegre, 2021
---

# Influência de $P$ no erro padrão {.allowframebreaks}

- A equação (2), da aula passada, mostra como a variância da porcentagem estimada muda com \structure{$P$} (a \structure{porcentagem da população na categoria $C$}), para \structure{$n$} e \structure{$N$} fixos. Se a cpf for ignorada, temos

$$
\Var(p) = \frac{PQ}{n}.
$$

- A função \structure{$PQ$} e sua raiz quadrada são mostradas a seguir.
    + Essas funções podem ser consideradas como variância e desvio padrão, respectivamente, para uma amostra de tamanho 1.
    
\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

P <- seq(from = 0, to = 100, by = 10)
Q <- 100 - P
PQ <- P*Q
sqrtPQ <- sqrt(PQ)

par(mfrow = c(1,2))
plot(P, PQ, type = "b", lwd = 2, col = "lightsalmon")
abline(h = seq(0, 2500, by = 500), v = P, col = "lightgrey", lty = 2)
plot(P, sqrtPQ, type = "b", lwd = 2, col = "lightsalmon", ylab = expression(sqrt(PQ)))
abline(h = seq(0, 50, by = 10), v = P, col = "lightgrey", lty = 2)
par(mfrow = c(1,1))

```

\framebreak

::: {.block}
### Observações

- As funções têm seus maiores valores quando a população é dividida igualmente entre as duas classes e são simétricas em relação a este ponto.
- O erro padrão de \structure{$p$} muda relativamente pouco quando \structure{$P$} está entre 30 e 70%.
- No valor máximo de \structure{$\sqrt{PQ}$}, 50, um tamanho de amostra de 100 é necessário para reduzir o erro padrão da estimativa para 5%.
- Para atingir um erro padrão de 1%, é necessário um tamanho de amostra de 2500.
:::

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

n <- 1:200
P <- 50
Q <- 100 - P
ep <- sqrt((P*Q)/n)

plot(n, ep,
     type = "l",
     lwd = 2,
     col = "steelblue",
     ylab = expression(sqrt(hat(Var)(p))),
     main = "Erro padrão de p em função de n, quando P = 50%")
abline(h = seq(0, 50, by = 5), v = seq(0, 200, by = 50), col = "lightgrey", lty = 2)

```

\framebreak

- Esta abordagem não é apropriada quando o interesse reside no \structure{número total} de unidades da população que estão na classe \structure{$C$}.
- Nesse caso, é mais natural perguntar: a estimativa provavelmente está correta dentro de, digamos, 7% do verdadeiro total?
- Assim, tendemos a pensar no erro padrão expresso como uma fração ou porcentagem do valor verdadeiro, \structure{$NP$}. A fração é

$$
\frac{\sigma_{N_p}}{NP} = \frac{N\sqrt{PQ}}{\sqrt{n}NP}\sqrt{\frac{N-n}{N-1}} = \frac{1}{\sqrt{n}}\sqrt{\frac{Q}{P}}\sqrt{\frac{N-n}{N-1}}.
$$

\framebreak

- Essa quantidade é chamada de \structure{coeficiente de variação} da estimativa.
- Se a cpf for ignorada, o coeficiente é \structure{$\sqrt{Q/nP}$}.
- A razão \structure{$\sqrt{Q/P}$}, que pode ser considerada o coeficiente de variação para uma amostra de tamanho 1, é mostrada a seguir.

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

P <- c(0, 0.1, 0.5, 1, 5, seq(from = 10, to = 90, by = 10))
Q <- 100 - P
cv <- sqrt(Q/P)

plot(P, cv,
     type = "b",
     lwd = 2,
     col = "steelblue",
     ylab = expression(sqrt(Q/P)))
abline(h = seq(0, 30, by = 5),
       v = seq(from = 0, to = 90, by = 10),
       col = "lightgrey", lty = 2)

```

\framebreak

- Para um tamanho de amostra fixo, o coeficiente de variação do total estimado na classe \structure{$C$} diminui continuamente à medida que a porcentagem verdadeira em \structure{$C$} aumenta.
- O coeficiente é alto quando \structure{$P$} é menor que 5%.
- Amostras muito grandes são necessárias para estimativas precisas do número total que possui qualquer atributo raro na população.
- Para \structure{$P$} = 1%, devemos ter \structure{$\sqrt{n} = 99$} para reduzir o coeficiente de variação da estimativa para 0,1 ou 10%.
    + Isso dá um tamanho de amostra de 9801.
    + A amostragem aleatória simples, ou qualquer método de amostragem que seja adaptado para propósitos gerais, é um método caro de estimar o número total de unidades de um tipo escasso.

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

raiz.n <- c(1:10, seq(20, 100, by = 20))
P <- 1
Q <- 100 - P
cv <- sqrt(Q/P) * (1/raiz.n)

plot(raiz.n, cv,
     type = "b",
     lwd = 2,
     col = "steelblue",
     xlab = expression(sqrt(n)),
     ylab = expression(sqrt(Q/nP)))
abline(h = seq(0, 10, by = 1),
       v = seq(from = 0, to = 100, by = 10),
       col = "lightgrey", lty = 2)

```

# Distribuição binomial {.allowframebreaks}

```{r message=FALSE, echo=FALSE, out.width="15%", purl=FALSE, fig.align='right'}

knitr::include_graphics(here::here("images", "bin.jpg"))

```

- Como a população é de um tipo particularmente simples, em que os \structure{$Y_i$} são 1 ou 0, podemos encontrar a \structure{distribuição de frequência real} da estimativa \structure{$p$} e não apenas sua __média__ e __variância__.

\framebreak

- A população contém $A$ unidades que estão na classe \structure{$C$} e \structure{$N - A$} unidades em \structure{$C'$}, em que \structure{$P = A/N$}.
- Se a primeira unidade sorteada estiver em \structure{$C$}, permanecerão na população unidades \structure{$A - 1$} em \structure{$C$} e \structure{$N - A$} em \structure{$C'$}.
- Assim, a proporção de unidades em \structure{$C$}, após o primeiro sorteio, muda ligeiramente para \structure{$(A - 1)/(N - 1)$}. 
- Alternativamente, se a primeira unidade selecionada estiver em \structure{$C'$}, a proporção em \structure{$C$} muda para \structure{$A/(N - 1)$}.

\framebreak

- Na amostragem sem reposição, a proporção continua mudando dessa forma ao longo do sorteio.
- Na presente seção, essas variações são ignoradas, ou seja, \structure{$P$} é considerado \structure{constante}.
- Isso equivale a supor que \structure{$A$} e \structure{$N - A$} \structure{são ambos grandes} em relação ao tamanho da amostra \structure{$n$} (ou que a amostragem é com reposição).

\framebreak

- Com essa suposição, o processo de sorteio da amostra consiste em uma série de \structure{$n$} tentativas, em cada uma das quais a probabilidade de que a unidade selecionada esteja em \structure{$C$} é \structure{$P$}.
- Esta situação dá origem à \structure{distribuição de frequência binomial} para o número de unidades em \structure{$C$} na amostra.
- A probabilidade de que a amostra contenha \structure{$a$} unidades em \structure{$C$} é

$$
\Pr(a) = \frac{n!}{a!(n - a)!}P^aQ^{n-a},\quad a = 0, 1, \ldots, n.
$$

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

plot(dbinom(x = 0:50, size = 50, prob = 0.2),
     type = "h",
     lwd = 2,
     col = "red",
     xlab = "a",
     ylab = "Pr(a)")
legend("topright", legend = c("n = 50", "P = 0.2"), bty = "n")

```

\framebreak

- A partir dessa expressão, podemos tabular a distribuição de frequência de \structure{$a$}, de \structure{$p = a/n$} ou do total estimado \structure{$Np$}.

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='80%'}

par(mfrow = c(1,2))

plot(x = (0:50)/50,
  y = dbinom(x = 0:50, size = 50, prob = 0.2),
     type = "h",
  lwd = 2,
     col = "blue",
     xlab = "p",
     ylab = "Pr(p)")
legend("topright", legend = c("n = 50", "P = 0.2"), bty = "n")

plot(x = (1000*(0:50))/50,
     y = dbinom(x = 0:50, size = 50, prob = 0.2),
     lwd = 2,
     type = "h",
     col = "black",
     xlab = "Np",
     ylab = "Pr(Np)")
legend("topright", legend = c("n = 50", "P = 0.2", "N = 1000"), bty = "n")

par(mfrow = c(1,1))

```

# Distribuição hipergeométrica {.allowframebreaks}

```{r message=FALSE, echo=FALSE, out.width="15%", purl=FALSE, fig.align='right'}

knitr::include_graphics(here::here("images", "hyp.jpg"))

```

- A distribuição de \structure{$p$} pode ser encontrada sem a suposição de que a população seja grande em relação à amostra.
- O número de unidades nas duas classes \structure{$C$} e \structure{$C'$} na população são \structure{$A$} e \structure{$A'$}, respectivamente.
- Vamos calcular a probabilidade de que os números correspondentes na amostra sejam \structure{$a$} e \structure{$a'$}, em que

$$
a+a'=n,\quad A+A'=N.
$$

\framebreak

- Na amostragem aleatória simples, cada uma das ${N\choose n}$ diferentes seleções de \structure{$n$} unidades de \structure{$N$} tem uma chance igual de ser sorteada.
- Para encontrar a probabilidade desejada, contamos quantas dessas amostras contêm exatamente \structure{$a$} unidades de \structure{$C$} e \structure{$a'$} de \structure{$C'$}.
- O número de seleções diferentes de \structure{$a$} unidades entre \structure{$A$} que está em \structure{$C$} é \structure{${A\choose a}$}, enquanto o número de seleções diferentes de \structure{$a'$} entre \structure{$A'$} é \structure{${A'\choose a'}$}.
- Cada seleção do primeiro tipo pode ser combinada com qualquer uma do segundo para dar uma amostra diferente do tipo necessário.
- O número total de amostras do tipo necessário é, portanto,

$$
{A\choose a}\times{A'\choose a'}.
$$

\framebreak

- Portanto, se uma amostra aleatória simples de tamanho \structure{$n$} for sorteada, a probabilidade de que seja do tipo necessário é

$$
\Pr(a, a'|A, A') = \frac{{A\choose a}{A'\choose a'}}{{N\choose n}}
$$

- Esta é a distribuição de frequência de \structure{$a$} ou \structure{$np$}, da qual a distribuição de \structure{$p$} é imediatamente derivada.
- A distribuição é chamada de \structure{distribuição hipergeométrica}.

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

plot(dhyper(k = 50, m = 200, n = 800, x = 0:50),
     type = "h",
     lwd = 2,
     col = "red",
     xlab = "a",
     ylab = "Pr(a, a'| A, A')")
legend("topright",
       legend = c("n = 50", "P = 0.2", "N = 1000", "A = 200", "A' = 800"),
       bty = "n")

```

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

par(mfrow = c(1,2))

plot(x = (0:50)/50,
     y = dhyper(k = 50, m = 200, n = 800, x = 0:50),
     type = "h",
     lwd = 2,
     col = "blue",
     xlab = "p",
     ylab = "Pr(p)")
legend("topright",
       legend = c("n = 50", "P = 0.2", "N = 1000", "A = 200", "A' = 800"),
       bty = "n")

plot(x = (1000*(0:50))/50,
     y = dhyper(k = 50, m = 200, n = 800, x = 0:50),
     lwd = 2,
     type = "h",
     col = "black",
     xlab = "Np",
     ylab = "Pr(Np)")
legend("topright",
       legend = c("n = 50", "P = 0.2", "N = 1000", "A = 200", "A' = 800"),
       bty = "n")

par(mfrow = c(1,1))
```

# A binomial é uma boa aproximação para a hipergeométrica?

## Qualidade da aproximação {.allowframebreaks}

- \structure{Relembrando:}
    - \structure{$P$} é considerado \structure{constante}.
    - Isso equivale a supor que \structure{$A$} e \structure{$N - A$} \structure{são ambos grandes} em relação ao tamanho da amostra \structure{$n$} \structure{(fração de amostragem é pequena)}.

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

plot(x = (0:50)/50,
     y = dhyper(k = 50, m = 200, n = 800, x = 0:50),
     type = "h",
     xlim = c(0, 0.5),
     lwd = 2,
     col = "blue",
     xlab = "p",
     ylab = "Pr(p)",
     main = "n = 50, P = 0.2, N = 1000, A = 200, A' = 800, f = 0.05")
lines(x = (0:50)/50,
      y = dbinom(x = 0:50, size = 50, prob = 0.2),
      type = "h",
      lwd = 1,
      lty = 2,
      col = "red")
legend("topright",
       lty = c(1, 2),
       lwd = c(2, 1),
       col = c("blue", "red"),
       legend = c("Hipergeométrica", "Binomial"),
       bty = "n")

```

\framebreak

```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width='100%'}

plot(x = (0:400)/400,
     y = dhyper(k = 400, m = 200, n = 800, x = 0:400),
     type = "h",
     lwd = 2,
     xlim = c(0.1, 0.3),
     col = "blue",
     xlab = "p",
     ylab = "Pr(p)",
     main = "n = 400, P = 0.2, N = 1000, A = 200, A' = 800, f = 0.4")
lines(x = (0:400)/400,
      y = dbinom(x = 0:400, size = 400, prob = 0.2),
      type = "h",
      lwd = 1,
      lty = 2,
      col = "red")
legend("topright",
       lty = c(1, 2),
       lwd = c(2, 1),
       col = c("blue", "red"),
       legend = c("Hipergeométrica", "Binomial"),
       bty = "n")

```

# Para casa

- Revisar os tópicos discutidos nesta aula.
- Como podemos obter as probabilidades referentes a distribuições binomial e hipergeométrica?

## Próxima aula

- Intervalos de confiança para $P$:
    + Aproximados e exato (a real batalha).

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='70%', out.height='50%', paged.print=FALSE, purl=FALSE}

knitr::include_graphics(here::here('images', 'bin_vs_hyp.jpg'))

```

## Por hoje é só!

\begin{center}
{\bf Bons estudos!}
\end{center}

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='50%', out.height='50%', paged.print=FALSE, purl=FALSE}

knitr::include_graphics(here::here('images', 'Statistically-Insignificant-final01.jpg'))

```

